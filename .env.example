# ============================================
# LLM Provider Configuration
# ============================================
# At least ONE of these is required for the system to work

# Groq (recommended for fast inference)
GROQ_API_KEY=your_groq_api_key_here

# OpenAI (for GPT-4 and other OpenAI models)
# OPENAI_API_KEY=your_openai_api_key_here

# Anthropic (for Claude models)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google (for Gemini models)
# GOOGLE_GENERATIVE_AI_API_KEY=your_google_api_key_here

# Local LLM (for self-hosted models via OpenAI-compatible API)
# LOCAL_LLM_BASE_URL=http://localhost:8080/v1

# ============================================
# Memgraph Database Configuration
# ============================================
# Connection settings for the regulatory knowledge graph

# Option 1: Using MEMGRAPH_URI (recommended)
MEMGRAPH_URI=bolt://localhost:7687

# Option 2: Using separate host/port (alternative)
# MEMGRAPH_HOST=localhost
# MEMGRAPH_PORT=7687

# Authentication (defaults to 'memgraph' if not specified)
# MEMGRAPH_USERNAME=memgraph
# MEMGRAPH_PASSWORD=memgraph

# Database name (defaults to 'memgraph')
# MEMGRAPH_DATABASE=memgraph

# ============================================
# MCP (Model Context Protocol) Configuration
# ============================================
# For Perplexity search and other MCP tools

# Perplexity API (for web search and discovery)
PERPLEXITY_API_KEY=your_perplexity_api_key_here

# MCP Gateway URL (if using custom gateway)
# MCP_GATEWAY_URL=http://localhost:8001

# MCP read-only mode (set to 'true' to prevent graph writes)
# MCP_READ_ONLY=false

# ============================================
# E2B Sandbox Configuration (Optional)
# ============================================
# Required only if using sandboxed code execution

# E2B_API_KEY=your_e2b_api_key_here
